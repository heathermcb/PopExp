{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "The purpose of this notebook, along with 01_data_setup_example.ipynb and 03_demo_explore_results.ipynb, is to provide a tutorial of how you may want to use the pop_exp pacakge functions.\n",
    "\n",
    "Please see 01_data_setup_example.ipynb before you work through this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "\n",
    "To recap, to demo all the functions available in pop_exp, in this notebook we'll\n",
    "do five separate things, which align with the five options available in three functions in the package. \n",
    "\n",
    "1. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018. \n",
    "2. Find the total number of people residing within 10 km of *EACH* US wildfire\n",
    "disaster in 2016, 2017, and 2018.\n",
    "3. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of *EACH* US wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "5. Find the population of all 2020 ZCTAs. \n",
    "\n",
    "In the last notebook, we prepared the wildfire disaster exposure data and ZCTA\n",
    "data to pass to the pop_exp functions so we could complete these computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do it\n",
    "\n",
    "We need to import some libraries and also install and import pop_exp. If you haven't installed pop_exp in the environment you're working in now, go ahead and activate that environment, and pip install pop_exp in the terminal. We can then import the functions within pop ex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing necessary libraries.\n",
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pop_exp import pop_ex_helpers as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also set some paths to make it easy to access the data we cleaned for \n",
    "this tutorial. \n",
    "\n",
    "To find the number of people affected by one or more wildfire disaster by year 2016-2018, and by ZCTA, we need to get the paths to each of our wildfire files that we made in the data setup notebook.\n",
    "\n",
    "The regular expression below selects all the files in the interim data directory that have 'fire' in the name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths \n",
    "base_path = pathlib.Path.cwd().parent\n",
    "data_dir = base_path / \"demo_data\"\n",
    "# wf paths regex\n",
    "wildfire_paths = glob.glob(str(data_dir / \"02_interim_data\" / \"*fire*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the path to the population raster we're using, and the ZCTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHSL pop raster\n",
    "ghsl_path = data_dir / \"01_raw_data\" / \"GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0.tif\"\n",
    "\n",
    "# ZCTA path \n",
    "zcta_path = glob.glob(str(data_dir / \"02_interim_data\" / \"*zcta*\"))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now set up to run the five cases we're interested in. \n",
    "\n",
    "Our first goal was:\n",
    "1. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018. \n",
    "\n",
    "To do this, we can run find_number_of_people_affected with the parameter \n",
    "by_unique_hazrad = False. \n",
    "\n",
    "Because we're looping over three years, we'll initialize an empty list first, \n",
    "and then store the results in this list. We're also adding a year variable to \n",
    "the result as we go. In total, this takes around 24 seconds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the function\n",
      "Reading data and finding best UTM projection for hazard geometries (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/pop_exp/pop_ex_helpers.py:39: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  ch_shp[\"centroid_lon\"] = ch_shp.centroid.x\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/pop_exp/pop_ex_helpers.py:40: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  ch_shp[\"centroid_lat\"] = ch_shp.centroid.y\n",
      "Buffering hazard geometries (2/4):  37%|███▋      | 107/291 [00:01<00:03, 61.28it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_affected_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     num_affected \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mfind_num_people_affected(\n\u001b[1;32m      5\u001b[0m         path_to_hazards\u001b[38;5;241m=\u001b[39mwildfire_paths[i],\n\u001b[1;32m      6\u001b[0m         raster_path\u001b[38;5;241m=\u001b[39mghsl_path,\n\u001b[1;32m      7\u001b[0m         by_unique_hazard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# setting by unique hazard to false \u001b[39;00m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     num_affected[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2016\u001b[39m \u001b[38;5;241m+\u001b[39m i\n\u001b[1;32m     10\u001b[0m     num_affected_list\u001b[38;5;241m.\u001b[39mappend(num_affected)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/pop_exp/pop_ex_helpers.py:344\u001b[0m, in \u001b[0;36mfind_num_people_affected\u001b[0;34m(path_to_hazards, raster_path, by_unique_hazard)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning the function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# prep data\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# get ID, hazard geom, best UTM, buffer dist, and buffered geom in WGS84\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m ch_df \u001b[38;5;241m=\u001b[39m prep_data(path_to_hazards\u001b[38;5;241m=\u001b[39mpath_to_hazards)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# find overlapping buffered hazards\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# select and rename columns in filtered_ch - ID, and set buffered hazard to be geom\u001b[39;00m\n\u001b[1;32m    348\u001b[0m ch_df \u001b[38;5;241m=\u001b[39m ch_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID_climate_hazard\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffered_hazard\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/pop_exp/pop_ex_helpers.py:164\u001b[0m, in \u001b[0;36mprep_data\u001b[0;34m(path_to_hazards, path_to_additional_geos)\u001b[0m\n\u001b[1;32m    161\u001b[0m     ad_geo \u001b[38;5;241m=\u001b[39m prep_geographies(path_to_additional_geos, geo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# add buffered hazard geometry col to climate hazards\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m ch_shp \u001b[38;5;241m=\u001b[39m add_buffered_geom_col(ch_shp)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_to_additional_geos:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ch_shp, ad_geo\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/pop_exp/pop_ex_helpers.py:132\u001b[0m, in \u001b[0;36madd_buffered_geom_col\u001b[0;34m(ch_df)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# buffer distance is in meters\u001b[39;00m\n\u001b[1;32m    131\u001b[0m buffer_dist \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 132\u001b[0m buffered_hazard_geometry \u001b[38;5;241m=\u001b[39m geom_series_utm\u001b[38;5;241m.\u001b[39mbuffer(buffer_dist)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# back to OG\u001b[39;00m\n\u001b[1;32m    134\u001b[0m buffered_hazard_geometry \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    135\u001b[0m     gpd\u001b[38;5;241m.\u001b[39mGeoSeries([buffered_hazard_geometry], crs\u001b[38;5;241m=\u001b[39mbest_utm)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m.\u001b[39mto_crs(ch_df\u001b[38;5;241m.\u001b[39mcrs)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    138\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/geopandas/base.py:5048\u001b[0m, in \u001b[0;36mGeoPandasBase.buffer\u001b[0;34m(self, distance, resolution, cap_style, join_style, mitre_limit, single_sided, **kwargs)\u001b[0m\n\u001b[1;32m   4974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuffer\u001b[39m(\n\u001b[1;32m   4975\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4976\u001b[0m     distance,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4982\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4983\u001b[0m ):\n\u001b[1;32m   4984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a ``GeoSeries`` of geometries representing all points within\u001b[39;00m\n\u001b[1;32m   4985\u001b[0m \u001b[38;5;124;03m    a given ``distance`` of each geometric object.\u001b[39;00m\n\u001b[1;32m   4986\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5046\u001b[0m \n\u001b[1;32m   5047\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5048\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _delegate_geo_method(\n\u001b[1;32m   5049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5050\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5051\u001b[0m         distance\u001b[38;5;241m=\u001b[39mdistance,\n\u001b[1;32m   5052\u001b[0m         resolution\u001b[38;5;241m=\u001b[39mresolution,\n\u001b[1;32m   5053\u001b[0m         cap_style\u001b[38;5;241m=\u001b[39mcap_style,\n\u001b[1;32m   5054\u001b[0m         join_style\u001b[38;5;241m=\u001b[39mjoin_style,\n\u001b[1;32m   5055\u001b[0m         mitre_limit\u001b[38;5;241m=\u001b[39mmitre_limit,\n\u001b[1;32m   5056\u001b[0m         single_sided\u001b[38;5;241m=\u001b[39msingle_sided,\n\u001b[1;32m   5057\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   5058\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/geopandas/base.py:119\u001b[0m, in \u001b[0;36m_delegate_geo_method\u001b[0;34m(op, this, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         kwargs[key] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(val)\n\u001b[1;32m    118\u001b[0m a_this \u001b[38;5;241m=\u001b[39m GeometryArray(this\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m--> 119\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(a_this, op)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeoSeries(data, index\u001b[38;5;241m=\u001b[39mthis\u001b[38;5;241m.\u001b[39mindex, crs\u001b[38;5;241m=\u001b[39mthis\u001b[38;5;241m.\u001b[39mcrs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/geopandas/array.py:812\u001b[0m, in \u001b[0;36mGeometryArray.buffer\u001b[0;34m(self, distance, resolution, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(distance, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m distance \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_geographic_crs(stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(\n\u001b[0;32m--> 812\u001b[0m     shapely\u001b[38;5;241m.\u001b[39mbuffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, distance, quad_segs\u001b[38;5;241m=\u001b[39mresolution, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    813\u001b[0m     crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrs,\n\u001b[1;32m    814\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/shapely/decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[1;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/wf/lib/python3.12/site-packages/shapely/constructive.py:180\u001b[0m, in \u001b[0;36mbuffer\u001b[0;34m(geometry, distance, quad_segs, cap_style, join_style, mitre_limit, single_sided, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(single_sided):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_sided only accepts scalar values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mbuffer(\n\u001b[1;32m    181\u001b[0m     geometry,\n\u001b[1;32m    182\u001b[0m     distance,\n\u001b[1;32m    183\u001b[0m     np\u001b[38;5;241m.\u001b[39mintc(quad_segs),\n\u001b[1;32m    184\u001b[0m     np\u001b[38;5;241m.\u001b[39mintc(cap_style),\n\u001b[1;32m    185\u001b[0m     np\u001b[38;5;241m.\u001b[39mintc(join_style),\n\u001b[1;32m    186\u001b[0m     mitre_limit,\n\u001b[1;32m    187\u001b[0m     np\u001b[38;5;241m.\u001b[39mbool_(single_sided),\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    189\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_affected_list = []\n",
    "\n",
    "for i in range(0, 2):\n",
    "    num_affected = px.find_num_people_affected(\n",
    "        path_to_hazards=wildfire_paths[i],\n",
    "        raster_path=ghsl_path,\n",
    "        by_unique_hazard=False # setting by unique hazard to false \n",
    "    )\n",
    "    num_affected['year'] = 2016 + i\n",
    "    num_affected_list.append(num_affected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we added a year variable to each output, we can concatonate these dataframes together, and then look at the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now we'll join those dataframes together. \n",
    "num_affected_df = pd.concat(num_affected_list, axis=0)\n",
    "num_affected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output has three columns: ID_hazard, num_people_affected, and year. \n",
    "We added year, but the other two are output from find_num_people_affected.\n",
    "\n",
    "To find the total number of people affected by any wildfire disaster by year, \n",
    "we could group this output dataframe by year and sum. But, we're about to do two more interesting examples, so we'll leave this output as is, and dive into the output from the later examples in the third section of this tutorial. \n",
    "\n",
    "In our output, one thing has changed: our ID_hazard column is not the same as \n",
    "the ID_hazard column that we started with. \n",
    "\n",
    "We wanted to count the number of people residing within 10km of *any* \n",
    "US wildfire disaster. There are some people who live within 10km of two or\n",
    "more wildfire disasters. Because we just wanted the total, we did not want to \n",
    "double count those people. When computing a total, rather than the number of \n",
    "people affected by each unique hazard, find_num_people_affected takes the unary \n",
    "union of any buffered hazards that are overlapping, and finds the total of \n",
    "everyone residing within that area. In the output, the hazard IDs of any \n",
    "overlapping hazards are concatenated. This avoids double counting, while still \n",
    "giving the user as much information about how many people lived near each \n",
    "hazard or group of hazards as possible. \n",
    "\n",
    "We can save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected.to_csv(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to find the total number of people residing within 10 km of \n",
    "*EACH* US wildfire disaster in 2016, 2017, and 2018. \n",
    "\n",
    "To do this, we also need to use find_num_people_affected, with all the same \n",
    "arguments except for by_unique_hazard. In this case, we set by_unique_hazard to \n",
    "True. This means that we will count the number of people within 10km of each \n",
    "wildfire disaster boundary, regardless of whether two or more exposed areas \n",
    "overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: NEED to suppress those warnings about centroids somehow, so that the \n",
    "# output is nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected_list_unique_hazard = []\n",
    "\n",
    "for i in range(0, 2):\n",
    "    num_affected_unique = px.find_num_people_affected(\n",
    "        path_to_hazards=wildfire_paths[i],\n",
    "        raster_path=ghsl_path,\n",
    "        by_unique_hazard=False # setting by unique hazard to false \n",
    "    )\n",
    "    num_affected['year'] = 2016 + i\n",
    "    num_affected_list_unique_hazard.append(num_affected_unique)\n",
    "\n",
    "num_affected_unique = pd.concat(num_affected_list_unique_hazard, axis=0)\n",
    "num_affected_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our output has three columns: ID_hazard, num_people_affected, and year. \n",
    "\n",
    "This time, the ID_hazard column is the same as the one we passed to this \n",
    "function. This time, if people lived within 10 km of one or more fires, they\n",
    "are counted in the total people affected by that fire. This means people may\n",
    "be double counted or triple or more. \n",
    "\n",
    "We can save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected.to_csv(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were two more ways we wanted to define exposure. These are analogous to \n",
    "the two quantities we just computed, but this time, we want to know these\n",
    "exposures by ZCTA. \n",
    "\n",
    "3. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of *EACH* US wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "\n",
    "To do this, we need to run find_number_of_people_affected_by_geo. \n",
    "\n",
    "First, we'll find the total number of people affected by ZCTA \n",
    "(by_unique_hazard = False).\n",
    "\n",
    "This time, because we need to read in the large ZCTA file, the run will take slightly longer. It should take about 3 minutes, with the majority of this run time being the time it takes to read in the ZCTA file. If you're running these functions on giant datasets, we recommend parallelizeing over space or time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected_list = []\n",
    "\n",
    "for i in range(0, 2):\n",
    "    num_affected = px.find_num_people_affected_by_geo(\n",
    "        path_to_hazards=wildfire_paths[i],\n",
    "        path_to_additional_geos=zcta_path,\n",
    "        raster_path=ghsl_path,\n",
    "        by_unique_hazard=False # setting by unique hazard to false \n",
    "    )\n",
    "    num_affected['year'] = 2016 + i\n",
    "    num_affected_list.append(num_affected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case where we were not computing by ZCTA, the results come with \n",
    "hazard ids for groups of overlapping hazards.\n",
    "\n",
    "Since we're interested in the total number of people affected by ZCTA, we'll \n",
    "group the output dataframe by ZCTA and year and sum over any hazard IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting all years into one dataframe\n",
    "num_affected_df = pd.concat(num_affected_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_num_af = num_affected_df.groupby([\"ID_spatial_unit\", \"year\"]).agg(\n",
    "     {\"num_people_affected\": \"sum\"}\n",
    ").reset_index()\n",
    "\n",
    "# And we can save \n",
    "agg_num_af.to_csv(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our final case of counting exposed people, in which we aim to find the number of people affected by each hazard by each ZCTA, we do the same as we just did, but with by_unique_hazard = True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected_list = []\n",
    "\n",
    "for i in range(0, 2):\n",
    "    num_affected = px.find_num_people_affected_by_geo(\n",
    "        path_to_hazards=wildfire_paths[i],\n",
    "        path_to_additional_geos=zcta_path,\n",
    "        raster_path=ghsl_path,\n",
    "        by_unique_hazard=True # setting by unique hazard to true \n",
    "    )\n",
    "    num_affected['year'] = 2016 + i\n",
    "    num_affected_list.append(num_affected)\n",
    "\n",
    "# all years in one dataframe\n",
    "num_affected_df = pd.concat(num_affected_list, axis=0)\n",
    "# and we can save\n",
    "agg_num_af.to_csv(data_dir / \"03_results\" / \"num_people_affected_by_wildfire.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore some of the output from these runs in the next section of the tutorial.  \n",
    "\n",
    "Finally, let's use the function find_number_of_people_residing_by_geo to get some denominators for our dataset. This function can help us use the gridded population data we used to find the number of people residing within the hazard buffers to also find the number of people residing in each ZCTA. This is useful if we're using a gridded population dataset that we think is a big improvement over other population counts in our additional spatial units, or we just want to be consistent. \n",
    "\n",
    "To call this function, all we need to do is use the same paths we've used previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_residing_by_zcta = px.find_number_of_people_residing_by_geo(\n",
    "    path_to_additional_geos=zcta_path,\n",
    "    raster_path=ghsl_path\n",
    ")\n",
    "\n",
    "num_residing_by_zcta.to_csv(data_dir / \"03_results\" / \"num_people_residing_by_zcta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please continue to part 3 of this tutorial to explore the output of these functions! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
