{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION: \n",
    "\n",
    "The purpose of this notebook, along with 02_run_example.ipynb, is to provide\n",
    "a tutorial of how you may want to use the pop_exp pacakge functions.\n",
    "\n",
    "This notebook cleans some raw data files for use in the pop_exp functions, \n",
    "and then 02_run_example.ipynb demonstrates how to use the pop_exp functions.\n",
    "\n",
    "Prerequisites: This tutorial for pop_exp assumes that you have a version of \n",
    "Python installed on your computer compatible with the requirements of pop_exp, \n",
    "you have an IDE, and youâ€™re able to open and run a Jupyter notebook as well as \n",
    "Python scripts. It also assumes that you are able to create and manage a virtual \n",
    "environment into which you have installed the Python package pop_exp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT WE ARE DOING HERE: \n",
    "\n",
    "This tutorial will teach you how to use pop exp to find the number of people \n",
    "affected by any wildfire disaster by ZCTA across the years 2016-2018. It will \n",
    "disucss in more detail how pop_exp allows you to define exposure in different \n",
    "ways shortly.  \n",
    "\n",
    "pop_exp is for population exposure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA USED IN THIS TUTORIAL:\n",
    "\n",
    "The functions in pop_exp allow the user to find the number of people who reside \n",
    "near environmental hazards like wildfires, either inside the hazard boundaries \n",
    "or within a buffer of the environmental hazard, using a dataset of hazards and \n",
    "a gridded population dataset. If the user wishes to find the number of people \n",
    "affected within additional spatial units such as ZCTAs or census tracts, a \n",
    "dataset describing those geographies is also required. \n",
    "\n",
    "In this example, we'll use a publicly available dataset of US wildfire disaster \n",
    "boundaries for the years 2016-2018 as our hazard data. A description of this \n",
    "data and a link for download is available here: \n",
    "\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/R73R85\n",
    "\n",
    "This tutorial will demonstrate how to find the number of people residing within\n",
    "a buffer of these wildfires by ZCTA, so we'll also use a shapefile of 2020 \n",
    "ZCTAs, described in detail and available for download here:\n",
    "\n",
    "https://www.census.gov/programs-surveys/geography/guidance/geo-areas/zctas.html\n",
    "\n",
    "For the required gridded population data, which is used by the function to \n",
    "determine how many people live where, we'll use the version of the Global Human\n",
    "Settlement Layer which describes the residential population of the globe at \n",
    "100 m resolution. It's downloadable here: \n",
    "\n",
    "https://human-settlement.emergency.copernicus.eu/download.php?ds=pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOALS OF FUNCTION USE: \n",
    "\n",
    "The Python package pop_exp can do five distinct computations. \n",
    "\n",
    "1. Find the total number of people who reside within a buffer distance (which \n",
    "can be 0) of *any* environmental hazard in a set of hazards.\n",
    "2. Find the total number of people who reside within a buffer distance (which \n",
    "can be 0) of *EACH* environmental hazard in a set of hazards.\n",
    "3. Find the total number of people who reside within a buffer distance (which \n",
    "can be 0) of *any* environmental hazard in a set of hazards, by additional spatial \n",
    "unit (ex. the total number of people who resided within 10km of any wildfire \n",
    "disaster in 2018 by ZCTA).\n",
    "4. Find the total number of people who reside within a buffer distance (which \n",
    "can be 0) of *EACH* environmental hazard in a set of hazards, by additional \n",
    "spatial unit. \n",
    "5. Find the number of people residing within each spatial unit according to a\n",
    "gridded population dataset. \n",
    "\n",
    "The fifth function is meant to provide denominators for computations conducted \n",
    "with the first 4. For example, you may want to find the total number of people \n",
    "who resided within 10km of any wildfire disaster in 2018 by ZCTA, and then \n",
    "calculate the proportion of the ZCTA population that was exposed. To do this, \n",
    "you could use a function in pop_exp to find the ZCTA population according to \n",
    "the gridded population raster you used to determine exposure. \n",
    "\n",
    "This tutorial will demonstrate all of these options. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo all the functions available in pop_exp, we will do five separate things,\n",
    "which align with the five options available in the package. \n",
    "\n",
    "1. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018. \n",
    "2. Find the total number of people residing within 10 km of *EACH* US wildfire\n",
    "disaster in 2016, 2017, and 2018.\n",
    "3. Find the total number of people residing within 10km of *any* US wildfire \n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of *EACH* US wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "5. Find the population of all 2020 ZCTAs. \n",
    "\n",
    "To do the first two computations, we need to call the pop_exp function \n",
    "find_number_of_people_affected. The function parameter by_unique_hazard allows\n",
    "us to specify whether we want to find the total number of people residing near \n",
    "*any* hazard, or *each* hazard. When by_unique_hazard = False, the function \n",
    "computes the number of people exposed to any hazard. When it's True, it computes\n",
    "a total for each unique hazard. \n",
    "\n",
    "To do the second computations, we'll call the function \n",
    "find_number_of_people_affected_by_geo. As with find_number_of_people_affected, \n",
    "when by_unique_hazard = False, the function computes the number of people \n",
    "exposed to any hazard by ZCTA, and when it's True, it computes\n",
    "a total number of people affected for each unique hazard by ZCTA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING:\n",
    "\n",
    "To prepare to do the above computations, we need to prepare the data. \n",
    "This is where we start coding! First we import some libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by preparing the wildfire data. We'll set directories, and then \n",
    "read in the raw wildfire data as downloaded from Harvard dataverse. Note that\n",
    "the raw data contains wildfire disasters for years 2000-2019, which is a lot, \n",
    "and we're going to filter down to only 2016-2018 for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path.cwd().parent\n",
    "data_dir = base_path / \"demo_data\"\n",
    "\n",
    "fires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wildfires_conus.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the data to make sure it read in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both find_num_people_affected, and find_number_of_people_affected_by_geo, \n",
    "when we run the functions, we need to pass a path to a hazard dataframe with \n",
    "3 columns:  ID_climate_hazard, buffer_dist, and geometry. So we need to decide \n",
    "on a buffer distance and create that column, and rename the other columns to \n",
    "the correct names. \n",
    "\n",
    "For this tutorial, I've decided I want to consider people exposed to a wildfire\n",
    "if they live within 10 km of the boundaries of the wildfire disasters that are\n",
    "specified in my dataset. You could do something different if you think the \n",
    "relevant distance from your hazard is different. You can also assign a buffer\n",
    "of 0 to your hazards, or different buffers to each hazard in your dataset. They\n",
    "don't all have to be the same.  \n",
    "\n",
    "The buffer distance is in meters, so we'll specify a 10,000 m buffer distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires[\"buffer_dist\"] = 10000 # buffer distance in in meters \n",
    "fires.head # Checking what columns I have in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a buffer distance column. We need to select and rename the\n",
    "remaining columns we need for pop_exp, but we also need to select the years \n",
    "we're interested in. \n",
    "\n",
    "I'm interested in years 2016-2018, and I've decided that I want to determine \n",
    "exposure by year. I want to compute the total number of people affected by any \n",
    "fire in 2016, 2017, and 2018, as well as the three other exposure definitions we\n",
    "wrote out above. \n",
    "\n",
    "There is no option in pop_exp to indicate which hazards are\n",
    "for which year, or time period. If I want to know the total number of people \n",
    "affected by hazards in 2016 but not 2017, I need to feed pop_exp the exposure\n",
    "data for 2016 along with a gridded population dataset that represents the \n",
    "population in 2016. If I wanted monthly exposure for 2016, I'd need to split\n",
    "my exposure data up by month and call the function separately on each month. \n",
    "\n",
    "So before selecting just the ID, hazard, and buffer distance columns, I'm \n",
    "going to select and split up the years I'm interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fires in 2016, 2017, 2018\n",
    "fires = fires[fires[\"wildfire_year\"].isin([2016, 2017, 2018])]\n",
    "# Split this into a list of dataframes by year\n",
    "fires_by_year = [fires[fires[\"wildfire_year\"] == year] for year in [2016, 2017, 2018]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my exposure datasets, I'll select and rename the columns I need\n",
    "for pop_exp: ID_climate_hazard, buffer_dist, and geometry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, select cols\n",
    "fires_by_year = [fire[[\"wildfire_id\", \"buffer_dist\", \"geometry\"]] for fire in fires_by_year]\n",
    "# Then rename the wildfire ID col\n",
    "fires_by_year = [fire.rename(columns={\"wildfire_id\": \"ID_climate_hazard\"}) for fire in fires_by_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm going to write these out into an interim data folder to call \n",
    "using the pop_exp function, since the pop_exp function requires you to pass \n",
    "a path name. I'm using geojson files because that's what the function requires. \n",
    "Parquet is also an option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fire in enumerate(fires_by_year):\n",
    "    fire.to_file(data_dir / \"02_interim_data\" / f\"wildfires_{2016 + i}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've dealt with the wildfire disaster exposure data which is going to be our\n",
    "\"hazard\" data for pop exp. Now we also need to get the ZCTA data into the right\n",
    "format. \n",
    "\n",
    "I'm using 2020 ZCTA data, since my years are closer to the 2020 census than the\n",
    "2010 census. I'm going to read in the data, and then select and rename the \n",
    "columns to be what the functions find_number_of_people_affected and \n",
    "find_number_of_people_affected_by_geo require. \n",
    "\n",
    "I need to rename the ZCTA ID to 'ID_spatial_unit'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm reading in the raw ZCTA data. \n",
    "zctas = gpd.read_parquet(data_dir / \"01_raw_data\" / \"zctas_2020.parquet\")\n",
    "# Rename \n",
    "zctas.rename(columns={\"zcta\": \"ID_spatial_unit\"}, inplace=True)\n",
    "zctas.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I'll save this as a geojson file as well. This additional spatial unit \n",
    "file can be in geojson or parquet format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a minute. \n",
    "zctas_path = data_dir / \"02_interim_data\" / \"zctas_2020.geojson\"\n",
    "zctas.to_file(zctas_path, driver = 'GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the gridded population raster doesn't require any preprocessing, our \n",
    "data is ready! Proceed to 02_run_example.ipynb to continue the tutorial. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
